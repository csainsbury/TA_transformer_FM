{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # outline and description of the project\n",
    "# **Introduction**\n",
    "\n",
    "# Designing a transformer-based, time-aware, self-supervised foundation model for medical EHR data is a complex task, but with careful planning and modular development, it's achievable. Below is a detailed step-by-step guide to help you develop this model, focusing initially on EHR data and structuring it to allow for the future inclusion of image data.\n",
    "\n",
    "# ---\n",
    "\n",
    "# **1. Architectural Overview**\n",
    "\n",
    "# Your model will consist of the following components:\n",
    "\n",
    "# - **Data Preprocessing Pipeline**\n",
    "#   - Handling of triplet data: `['data_type', 'value', 'timestamp']`\n",
    "#   - Encoding of categorical and continuous variables\n",
    "#   - Time embedding to capture temporal information\n",
    "\n",
    "# - **Transformer Encoder**\n",
    "#   - Self-attention mechanism adapted for time-series data\n",
    "#   - Positional encoding modified for irregular time intervals\n",
    "#   - Ability to handle variable-length sequences\n",
    "\n",
    "# - **Self-Supervised Learning Objective**\n",
    "#   - Masked Reconstruction (similar to BERT's MLM)\n",
    "#   - Contrastive Learning (e.g., SimCLR adaptation for time-series)\n",
    "\n",
    "# - **Output Layer**\n",
    "#   - Generates embeddings for downstream tasks\n",
    "#   - Interface for adding classification/regression heads\n",
    "\n",
    "# - **Modularity for Future Extensions**\n",
    "#   - Design the model to easily incorporate additional modalities (e.g., images)\n",
    "\n",
    "# ---\n",
    "\n",
    "# **2. Step-by-Step Development Guide**\n",
    "\n",
    "# **Step 1: Data Preparation**\n",
    "\n",
    "# *Objective:* Prepare your data in a format suitable for transformer input.\n",
    "\n",
    "# - **1.1 Data Collection**\n",
    "#   - Collect the triplet data: `['data_type', 'value', 'timestamp']` for each patient.\n",
    "#   - Ensure that the data is anonymized and complies with all relevant regulations.\n",
    "\n",
    "# - **1.2 Handling Missing Data**\n",
    "#   - Since you're avoiding imputation, represent missing data explicitly.\n",
    "#   - Introduce a special token or value to indicate missingness.\n",
    "\n",
    "# - **1.3 Encoding Data Types**\n",
    "#   - **Categorical Variables:**\n",
    "#     - Use embeddings for categorical `data_type`.\n",
    "#     - Assign a unique index to each `data_type` and initialize a learnable embedding matrix.\n",
    "#   - **Continuous Variables:**\n",
    "#     - Normalize or standardize the `value` field.\n",
    "#     - You may embed continuous values directly or use techniques like discretization followed by embedding.\n",
    "\n",
    "# - **1.4 Time Encoding**\n",
    "#   - Compute the time differences between events to capture temporal gaps.\n",
    "#   - Use relative time embeddings:\n",
    "#     - Create a function that maps time differences to embeddings.\n",
    "#     - Alternatively, use continuous time embeddings like Time2Vec.\n",
    "\n",
    "# - **1.5 Sequence Construction**\n",
    "#   - For each patient, sort events chronologically.\n",
    "#   - Construct sequences of triplets ready for model input.\n",
    "\n",
    "# **Step 2: Model Architecture**\n",
    "\n",
    "# *Objective:* Build a transformer model tailored for irregular time-series data.\n",
    "\n",
    "# - **2.1 Input Layer**\n",
    "#   - **Embedding Layer:**\n",
    "#     - Embed `data_type` and `value`.\n",
    "#     - Combine embeddings with time embeddings.\n",
    "#     - Concatenate or sum the embeddings to get a unified representation.\n",
    "\n",
    "# - **2.2 Positional Encoding**\n",
    "#   - Modify standard positional encoding to handle irregular time intervals.\n",
    "#   - Options include:\n",
    "#     - **Relative Positional Encoding:**\n",
    "#       - Use the time difference between events.\n",
    "#     - **Continuous Positional Encoding:**\n",
    "#       - Apply functions like sine and cosine to the time stamps.\n",
    "\n",
    "# - **2.3 Transformer Encoder Layers**\n",
    "#   - Stack multiple transformer encoder layers.\n",
    "#   - Adjust attention mechanisms to account for time information.\n",
    "#     - **Time-Aware Attention:**\n",
    "#       - Incorporate time embeddings into the attention calculations.\n",
    "#       - Modify the attention score to decay with increasing time gaps (e.g., using a time-decay function).\n",
    "\n",
    "# - **2.4 Output Layer**\n",
    "#   - **Sequence Output:**\n",
    "#     - Obtain embeddings for each time step.\n",
    "#   - **Pooling Layer:**\n",
    "#     - Apply pooling (e.g., mean, max) to get a fixed-size patient-level embedding.\n",
    "#   - **Embedding Vector:**\n",
    "#     - Use this vector for downstream tasks.\n",
    "\n",
    "# **Step 3: Self-Supervised Learning Objective**\n",
    "\n",
    "# *Objective:* Train the model to learn meaningful representations without labeled data.\n",
    "\n",
    "# - **3.1 Masked Reconstruction (Masked Modeling)**\n",
    "#   - Randomly mask portions of the input data (e.g., `value` or `data_type`).\n",
    "#   - The model tries to reconstruct the masked parts.\n",
    "#   - **Implementation:**\n",
    "#     - Create a masking function that selects random positions to mask.\n",
    "#     - Use a special token or value to indicate masked elements.\n",
    "\n",
    "# - **3.2 Contrastive Learning**\n",
    "#   - Generate positive and negative pairs by data augmentation.\n",
    "#   - The model learns to distinguish between similar and dissimilar sequences.\n",
    "#   - **Implementation:**\n",
    "#     - Apply transformations like jittering, scaling, or time warping to create augmented sequences.\n",
    "#     - Use a contrastive loss function (e.g., InfoNCE).\n",
    "\n",
    "# - **3.3 Loss Functions**\n",
    "#   - **Masked Reconstruction Loss:**\n",
    "#     - Use cross-entropy for categorical variables.\n",
    "#     - Use mean squared error for continuous variables.\n",
    "#   - **Contrastive Loss:**\n",
    "#     - Implement the contrastive loss appropriate for your contrastive learning setup.\n",
    "\n",
    "# **Step 4: Training Procedure**\n",
    "\n",
    "# *Objective:* Train the model efficiently, starting on limited hardware.\n",
    "\n",
    "# - **4.1 Training on 3090Ti**\n",
    "#   - **Batch Size:**\n",
    "#     - Start with a small batch size that fits in memory.\n",
    "#   - **Gradient Accumulation:**\n",
    "#     - Accumulate gradients over multiple batches to simulate a larger batch size.\n",
    "#   - **Mixed Precision Training:**\n",
    "#     - Use FP16 precision to reduce memory usage.\n",
    "\n",
    "# - **4.2 Scaling Up on A100-80G**\n",
    "#   - Increase batch size and model complexity as allowed by increased memory.\n",
    "#   - Consider using multi-GPU training if available.\n",
    "\n",
    "# - **4.3 Optimization Techniques**\n",
    "#   - Use learning rate schedulers (e.g., warm-up followed by decay).\n",
    "#   - Monitor training with validation metrics.\n",
    "\n",
    "# **Step 5: Model Evaluation and Fine-Tuning**\n",
    "\n",
    "# *Objective:* Prepare the model for downstream predictive tasks.\n",
    "\n",
    "# - **5.1 Embedding Extraction**\n",
    "#   - Extract embeddings from the trained model for each patient.\n",
    "#   - Save embeddings for use in downstream tasks.\n",
    "\n",
    "# - **5.2 Adding Task-Specific Heads**\n",
    "#   - **Classification Head:**\n",
    "#     - For binary or multi-class classification tasks.\n",
    "#     - Use a simple feed-forward network on top of embeddings.\n",
    "#   - **Regression Head:**\n",
    "#     - For predicting continuous outcomes.\n",
    "#     - Similarly, use a feed-forward network.\n",
    "\n",
    "# - **5.3 Fine-Tuning**\n",
    "#   - Optionally fine-tune the entire model or just the task-specific head on labeled data.\n",
    "#   - Use appropriate loss functions for the tasks.\n",
    "\n",
    "# **Step 6: Incorporating Additional Features**\n",
    "\n",
    "# *Objective:* Ensure that new data types can be added without significant rework.\n",
    "\n",
    "# - **6.1 Modular Design**\n",
    "#   - Structure your code to allow easy addition of new `data_type` entries.\n",
    "#   - Use configuration files or dictionaries to manage `data_type` mappings.\n",
    "\n",
    "# - **6.2 Embedding Layers**\n",
    "#   - When adding new features, expand the embedding layers accordingly.\n",
    "#   - Initialize new embeddings properly (e.g., random initialization or based on similar existing embeddings).\n",
    "\n",
    "# - **6.3 Re-Training or Fine-Tuning**\n",
    "#   - Decide whether to retrain the model from scratch or fine-tune it with the new features.\n",
    "#   - Consider the impact on the existing learned representations.\n",
    "\n",
    "# **Step 7: Stretch Goal - Generating Synthetic Data**\n",
    "\n",
    "# *Objective:* Extend the model to generate realistic synthetic data.\n",
    "\n",
    "# - **7.1 Generative Modeling**\n",
    "#   - Use models like Variational Autoencoders (VAEs) or Generative Adversarial Networks (GANs).\n",
    "#   - Adapt these models for sequential, time-series data.\n",
    "\n",
    "# - **7.2 Model Integration**\n",
    "#   - Incorporate the generative model into your existing architecture.\n",
    "#   - Use the encoder for embeddings and add a decoder for data generation.\n",
    "\n",
    "# - **7.3 Training the Generative Model**\n",
    "#   - Train the model to reconstruct input sequences or generate new sequences from latent variables.\n",
    "#   - Evaluate the quality of synthetic data using statistical measures and domain expert assessment.\n",
    "\n",
    "# ---\n",
    "\n",
    "# **3. Suggestions to Improve the Plan**\n",
    "\n",
    "# - **Leverage Existing Libraries**\n",
    "\n",
    "#   - Use libraries like **PyTorch** or **TensorFlow** for model development.\n",
    "#   - Consider specialized libraries for time-series transformers, such as **PyTorch Forecasting** or **HuggingFace's Transformers** adapted for time series.\n",
    "\n",
    "# - **Data Augmentation**\n",
    "\n",
    "#   - Enhance your training data with augmentation techniques suitable for time-series data.\n",
    "#   - This can improve model robustness and performance.\n",
    "\n",
    "# - **Handling Irregular Time Intervals**\n",
    "\n",
    "#   - Investigate models specifically designed for irregular time-series data, such as the **Temporal Fusion Transformer** or **Transformers with Continuous-Time Models**.\n",
    "\n",
    "# - **Evaluation Metrics**\n",
    "\n",
    "#   - Define appropriate metrics for self-supervised learning to monitor training progress.\n",
    "#   - For downstream tasks, use domain-specific metrics (e.g., ROC-AUC for classification).\n",
    "\n",
    "# - **Documentation and Code Structure**\n",
    "\n",
    "#   - Keep your code well-documented to facilitate future modifications.\n",
    "#   - Use version control systems like **Git** for tracking changes.\n",
    "\n",
    "# - **Collaboration and Reproducibility**\n",
    "\n",
    "#   - Consider sharing parts of your code and findings with the research community.\n",
    "#   - Ensure that your experiments are reproducible by setting random seeds and documenting the environment setup.\n",
    "\n",
    "# ---\n",
    "\n",
    "# **4. Future Integration of Image Data**\n",
    "\n",
    "# - **Modular Embedding Layer for Images**\n",
    "\n",
    "#   - Develop a separate image encoder (e.g., using CNNs or Vision Transformers).\n",
    "#   - Extract image embeddings that can be combined with EHR embeddings.\n",
    "\n",
    "# - **Fusion Techniques**\n",
    "\n",
    "#   - Explore methods to fuse embeddings from different modalities.\n",
    "#   - Options include concatenation, attention-based fusion, or gating mechanisms.\n",
    "\n",
    "# - **Unified Model Training**\n",
    "\n",
    "#   - Train the multimodal model end-to-end if computational resources allow.\n",
    "#   - Alternatively, train modality-specific encoders separately and combine them during fine-tuning.\n",
    "\n",
    "# ---\n",
    "\n",
    "# **Conclusion**\n",
    "\n",
    "# By following this detailed guide, you should be able to develop a transformer-based, time-aware, self-supervised foundation model for EHR data. The key is to start with a solid, modular design that allows for scalability and the addition of new features and modalities. Remember to test your model thoroughly at each stage and to document your process for future reference.\n",
    "\n",
    "# **Next Steps:**\n",
    "\n",
    "# - Begin implementing the data preprocessing pipeline.\n",
    "# - Prototype a simple version of the transformer model and test it on a small subset of data.\n",
    "# - Gradually expand the model complexity and the size of the dataset as you move from the 3090Ti to the A100-80G.\n",
    "# - Keep in mind the stretch goal of synthetic data generation and plan for its integration in later stages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-08 19:40:26,082 - INFO - Fitting normalizers...\n",
      "2024-10-08 19:40:30,064 - INFO - Preprocessing data...\n",
      "Processing patients: 100%|██████████| 117081/117081 [03:43<00:00, 523.33it/s] \n",
      "2024-10-08 19:44:14,596 - INFO - \n",
      "Preprocessed data for 117081 patients\n",
      "2024-10-08 19:44:14,600 - INFO - \n",
      "Sample data for patient 2147483663:\n",
      "2024-10-08 19:44:14,600 - INFO - patient_id: 2147483663\n",
      "2024-10-08 19:44:14,600 - INFO - data_type: torch.Size([40])\n",
      "2024-10-08 19:44:14,601 - INFO - value: torch.Size([40])\n",
      "2024-10-08 19:44:14,601 - INFO - timestamp: torch.Size([40])\n",
      "2024-10-08 19:44:14,601 - INFO - time_diff: torch.Size([40])\n",
      "2024-10-08 19:44:14,601 - INFO - mask: torch.Size([40])\n",
      "2024-10-08 19:44:14,601 - INFO - missing: torch.Size([40])\n"
     ]
    }
   ],
   "source": [
    "# Data Preprocessing Section\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List, Dict, Tuple\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from datetime import datetime\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Suppress sklearn warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "class EHRDataPreprocessor:\n",
    "    def __init__(self, data_path: str, feature_files: List[str], demographic_file: str, max_seq_length: int):\n",
    "        self.data_path = Path(data_path)\n",
    "        self.feature_files = feature_files\n",
    "        self.demographic_file = demographic_file\n",
    "        self.max_seq_length = max_seq_length\n",
    "        self.data_types = self._get_data_types()\n",
    "        self.data_type_to_idx = {dt: idx for idx, dt in enumerate(self.data_types)}\n",
    "        self.value_normalizer = ValueNormalizer()\n",
    "        self.reference_date = datetime(2000, 1, 1)\n",
    "        self.continuous_features = ['hba1c', 'sbp', 'bmi', 'creat']\n",
    "        self.categorical_features = []\n",
    "\n",
    "    def _get_data_types(self) -> List[str]:\n",
    "        return [file.split('.')[0] for file in self.feature_files] + ['demographics']\n",
    "\n",
    "    def load_and_preprocess_data(self) -> Dict[int, Dict[str, torch.Tensor]]:\n",
    "        feature_data = self._load_feature_data()\n",
    "        demographic_data = self._load_demographic_data()\n",
    "        \n",
    "        logging.info(\"Fitting normalizers...\")\n",
    "        self.value_normalizer.fit(feature_data, demographic_data)\n",
    "        \n",
    "        logging.info(\"Preprocessing data...\")\n",
    "        preprocessed_data = {}\n",
    "        for patient_id in tqdm(feature_data.keys(), desc=\"Processing patients\"):\n",
    "            patient_feature_data = feature_data[patient_id]\n",
    "            patient_demographic_data = demographic_data.get(patient_id, {})\n",
    "            try:\n",
    "                preprocessed_data[patient_id] = self.preprocess_patient_data(patient_id, patient_feature_data, patient_demographic_data)\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error processing patient {patient_id}: {str(e)}\")\n",
    "        \n",
    "        return preprocessed_data\n",
    "\n",
    "    def _load_feature_data(self) -> Dict[int, List[Tuple[str, float, float]]]:\n",
    "        feature_data = {}\n",
    "        for file in self.feature_files:\n",
    "            df = pd.read_csv(self.data_path / file)\n",
    "            feature_name = file.split('.')[0]\n",
    "            for _, row in df.iterrows():\n",
    "                patient_id = int(row['patient_id'])\n",
    "                if patient_id not in feature_data:\n",
    "                    feature_data[patient_id] = []\n",
    "                timestamp = (datetime.strptime(row['timestamp'], '%Y-%m-%d') - self.reference_date).days\n",
    "                value = row['value'] if pd.notna(row['value']) else None\n",
    "                feature_data[patient_id].append((feature_name, value, float(timestamp)))\n",
    "        return feature_data\n",
    "\n",
    "    def _load_demographic_data(self) -> Dict[int, Dict[str, str]]:\n",
    "        df = pd.read_csv(self.data_path / self.demographic_file)\n",
    "        return {int(row['patient_id']): {col: str(row[col]) for col in df.columns if col != 'patient_id'} for _, row in df.iterrows()}\n",
    "\n",
    "    def preprocess_patient_data(self, patient_id: int, feature_data: List[Tuple[str, float, float]], demographic_data: Dict[str, str]) -> Dict[str, torch.Tensor]:\n",
    "        feature_data.sort(key=lambda x: x[2])\n",
    "        seq_length = min(len(feature_data) + 1, self.max_seq_length)\n",
    "        data_type_tensor = torch.zeros(seq_length, dtype=torch.long)\n",
    "        value_tensor = torch.zeros(seq_length)\n",
    "        time_tensor = torch.zeros(seq_length)\n",
    "        mask_tensor = torch.zeros(seq_length, dtype=torch.bool)\n",
    "        missing_tensor = torch.zeros(seq_length, dtype=torch.bool)\n",
    "\n",
    "        for i, (data_type, value, timestamp) in enumerate(feature_data[:seq_length - 1]):\n",
    "            data_type_tensor[i] = self.data_type_to_idx[data_type]\n",
    "            if value is not None:\n",
    "                value_tensor[i] = self.value_normalizer.normalize(data_type, value)\n",
    "                mask_tensor[i] = True\n",
    "            else:\n",
    "                missing_tensor[i] = True\n",
    "            time_tensor[i] = timestamp\n",
    "\n",
    "        demo_idx = seq_length - 1\n",
    "        data_type_tensor[demo_idx] = self.data_type_to_idx['demographics']\n",
    "        value_tensor[demo_idx] = self.value_normalizer.normalize_demographics(demographic_data)\n",
    "        time_tensor[demo_idx] = time_tensor[demo_idx - 1] if demo_idx > 0 else 0\n",
    "        mask_tensor[demo_idx] = True\n",
    "\n",
    "        time_diff_tensor = torch.zeros_like(time_tensor)\n",
    "        time_diff_tensor[1:] = time_tensor[1:] - time_tensor[:-1]\n",
    "\n",
    "        return {\n",
    "            'patient_id': patient_id,\n",
    "            'data_type': data_type_tensor,\n",
    "            'value': value_tensor,\n",
    "            'timestamp': time_tensor,\n",
    "            'time_diff': time_diff_tensor,\n",
    "            'mask': mask_tensor,\n",
    "            'missing': missing_tensor\n",
    "        }\n",
    "\n",
    "class ValueNormalizer:\n",
    "    def __init__(self):\n",
    "        self.feature_scalers = {}\n",
    "        self.demographic_encoder = None\n",
    "        self.demographic_scaler = None\n",
    "        self.reference_date = datetime(2000, 1, 1)\n",
    "        self.demographic_columns = []\n",
    "\n",
    "    def fit(self, feature_data: Dict[int, List[Tuple[str, float, float]]], demographic_data: Dict[int, Dict[str, str]]):\n",
    "        feature_values = {feature: [] for feature in set(data_type for patient in feature_data.values() for data_type, _, _ in patient)}\n",
    "        for patient_data in feature_data.values():\n",
    "            for data_type, value, _ in patient_data:\n",
    "                if value is not None:\n",
    "                    feature_values[data_type].append(value)\n",
    "        \n",
    "        for feature, values in feature_values.items():\n",
    "            self.feature_scalers[feature] = StandardScaler().fit(np.array(values).reshape(-1, 1))\n",
    "\n",
    "        demographic_df = pd.DataFrame(demographic_data).T\n",
    "        self.demographic_columns = demographic_df.columns.tolist()\n",
    "\n",
    "        demographic_df['age'] = (pd.to_datetime(demographic_df['DOB'], errors='coerce') - self.reference_date).dt.days / 365.25\n",
    "        demographic_df['years_since_diagnosis'] = (pd.to_datetime(demographic_df['date_diagnosis'], errors='coerce') - self.reference_date).dt.days / 365.25\n",
    "        \n",
    "        categorical_columns = ['dm_type', 'sex', 'ethCode']\n",
    "        \n",
    "        self.demographic_encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "        self.demographic_encoder.fit(demographic_df[categorical_columns])\n",
    "        \n",
    "        numerical_columns = ['age', 'years_since_diagnosis']\n",
    "        self.demographic_scaler = StandardScaler().fit(demographic_df[numerical_columns].fillna(0))\n",
    "\n",
    "    def normalize(self, data_type: str, value: float) -> float:\n",
    "        if data_type in self.feature_scalers:\n",
    "            return self.feature_scalers[data_type].transform([[value]])[0][0]\n",
    "        else:\n",
    "            return value\n",
    "\n",
    "    def normalize_demographics(self, demographic_data: Dict[str, str]) -> float:\n",
    "        try:\n",
    "            dob = pd.to_datetime(demographic_data.get('DOB', '2000-01-01'), errors='coerce')\n",
    "            diagnosis_date = pd.to_datetime(demographic_data.get('date_diagnosis', '2000-01-01'), errors='coerce')\n",
    "            \n",
    "            age = (self.reference_date - dob).days / 365.25 if pd.notnull(dob) else 0\n",
    "            years_since_diagnosis = (self.reference_date - diagnosis_date).days / 365.25 if pd.notnull(diagnosis_date) else 0\n",
    "            \n",
    "            categorical_data = [\n",
    "                demographic_data.get('dm_type', 'Unknown'),\n",
    "                demographic_data.get('sex', 'Unknown'),\n",
    "                demographic_data.get('ethCode', 'Unknown')\n",
    "            ]\n",
    "            \n",
    "            encoded_categorical = self.demographic_encoder.transform([categorical_data])\n",
    "            scaled_numerical = self.demographic_scaler.transform([[age, years_since_diagnosis]])\n",
    "            \n",
    "            all_features = np.concatenate([encoded_categorical.flatten(), scaled_numerical.flatten()])\n",
    "            \n",
    "            return float(np.mean(all_features))\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error in normalize_demographics: {str(e)}\")\n",
    "            logging.error(f\"Demographic data: {demographic_data}\")\n",
    "            return 0.0\n",
    "\n",
    "# Example usage\n",
    "data_path = \"./processed_data\"\n",
    "feature_files = [\"hba1c.csv\", \"sbp.csv\", \"bmi.csv\", \"creat.csv\"]\n",
    "demographic_file = \"demographics.csv\"\n",
    "max_seq_length = 40\n",
    "\n",
    "preprocessor = EHRDataPreprocessor(data_path, feature_files, demographic_file, max_seq_length)\n",
    "preprocessed_data = preprocessor.load_and_preprocess_data()\n",
    "\n",
    "logging.info(f\"\\nPreprocessed data for {len(preprocessed_data)} patients\")\n",
    "first_patient_id = list(preprocessed_data.keys())[0]\n",
    "logging.info(f\"\\nSample data for patient {first_patient_id}:\")\n",
    "for key, value in preprocessed_data[first_patient_id].items():\n",
    "    if isinstance(value, torch.Tensor):\n",
    "        logging.info(f\"{key}: {value.shape}\")\n",
    "    else:\n",
    "        logging.info(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n",
      "0\n",
      "<torch.cuda.device object at 0x7f5b56267bb0>\n",
      "NVIDIA GeForce RTX 3090 Ti\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.current_device())\n",
    "print(torch.cuda.device(0))\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys in batch: dict_keys(['patient_id', 'data_type', 'value', 'timestamp', 'time_diff', 'mask', 'missing', 'attention_mask', 'lengths'])\n",
      "Patient IDs shape: torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Sampler\n",
    "import random\n",
    "\n",
    "class EHRDataset(Dataset):\n",
    "    def __init__(self, preprocessed_data):\n",
    "        self.data = list(preprocessed_data.values())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        return {\n",
    "            'patient_id': item['patient_id'],\n",
    "            'data_type': item['data_type'],\n",
    "            'value': item['value'],\n",
    "            'timestamp': item['timestamp'],\n",
    "            'time_diff': item['time_diff'],\n",
    "            'mask': item['mask'],\n",
    "            'missing': item['missing']\n",
    "        }\n",
    "\n",
    "def collate_fn(batch):\n",
    "    batch = sorted(batch, key=lambda x: len(x['data_type']), reverse=True)\n",
    "    \n",
    "    lengths = [len(item['data_type']) for item in batch]\n",
    "    max_len = max(lengths)\n",
    "\n",
    "    padded_batch = {\n",
    "        'patient_id': torch.tensor([item['patient_id'] for item in batch]),\n",
    "        'data_type': pad_sequence([item['data_type'] for item in batch], batch_first=True, padding_value=0),\n",
    "        'value': pad_sequence([item['value'] for item in batch], batch_first=True, padding_value=0.0),\n",
    "        'timestamp': pad_sequence([item['timestamp'] for item in batch], batch_first=True, padding_value=0.0),\n",
    "        'time_diff': pad_sequence([item['time_diff'] for item in batch], batch_first=True, padding_value=0.0),\n",
    "        'mask': pad_sequence([item['mask'] for item in batch], batch_first=True, padding_value=False),\n",
    "        'missing': pad_sequence([item['missing'] for item in batch], batch_first=True, padding_value=True)\n",
    "    }\n",
    "\n",
    "    attention_mask = torch.zeros(len(batch), max_len, dtype=torch.bool)\n",
    "    for i, length in enumerate(lengths):\n",
    "        attention_mask[i, :length] = 1\n",
    "\n",
    "    padded_batch['attention_mask'] = attention_mask\n",
    "    padded_batch['lengths'] = torch.tensor(lengths)\n",
    "\n",
    "    return padded_batch\n",
    "\n",
    "class PatientSampler(Sampler):\n",
    "    def __init__(self, dataset, batch_size, drop_last=False):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.drop_last = drop_last\n",
    "        self.patient_to_indices = self._create_patient_to_indices()\n",
    "\n",
    "    def _create_patient_to_indices(self):\n",
    "        patient_to_indices = {}\n",
    "        for idx, item in enumerate(self.dataset.data):\n",
    "            patient_id = item['patient_id']\n",
    "            if patient_id not in patient_to_indices:\n",
    "                patient_to_indices[patient_id] = []\n",
    "            patient_to_indices[patient_id].append(idx)\n",
    "        return patient_to_indices\n",
    "\n",
    "    def __iter__(self):\n",
    "        batches = []\n",
    "        patients = list(self.patient_to_indices.keys())\n",
    "        random.shuffle(patients)\n",
    "        \n",
    "        current_batch = []\n",
    "        for patient in patients:\n",
    "            indices = self.patient_to_indices[patient]\n",
    "            if len(indices) >= 2:\n",
    "                # Add two instances of the same patient to ensure positive pairs\n",
    "                current_batch.extend(random.sample(indices, 2))\n",
    "            elif len(indices) == 1:\n",
    "                # If only one instance, add it twice\n",
    "                current_batch.extend(indices * 2)\n",
    "            \n",
    "            if len(current_batch) >= self.batch_size:\n",
    "                batches.append(current_batch[:self.batch_size])\n",
    "                current_batch = current_batch[self.batch_size:]\n",
    "        \n",
    "        if not self.drop_last and current_batch:\n",
    "            batches.append(current_batch)\n",
    "        \n",
    "        random.shuffle(batches)\n",
    "        return iter(batches)\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.drop_last:\n",
    "            return len(self.dataset) // self.batch_size\n",
    "        else:\n",
    "            return (len(self.dataset) + self.batch_size - 1) // self.batch_size\n",
    "\n",
    "\n",
    "# Create the dataset\n",
    "dataset = EHRDataset(preprocessed_data)\n",
    "\n",
    "# Create the patient sampler\n",
    "patient_sampler = PatientSampler(dataset, batch_size=2)\n",
    "\n",
    "# Create the dataloader\n",
    "dataloader = DataLoader(dataset, batch_sampler=patient_sampler, collate_fn=collate_fn)\n",
    "\n",
    "# Verify that patient_id is included in the batch\n",
    "for batch in dataloader:\n",
    "    print(\"Keys in batch:\", batch.keys())\n",
    "    print(\"Patient IDs shape:\", batch['patient_id'].shape)\n",
    "    break  # Just check the first batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Mask shape: torch.Size([512, 40])\n",
      "Output shape: torch.Size([512, 40, 128])\n"
     ]
    }
   ],
   "source": [
    "# Model Architecture Section\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "class TimeAwareMultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super().__init__()\n",
    "        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.d_k = d_model // num_heads\n",
    "        \n",
    "        self.W_q = nn.Linear(d_model, d_model)\n",
    "        self.W_k = nn.Linear(d_model, d_model)\n",
    "        self.W_v = nn.Linear(d_model, d_model)\n",
    "        self.W_o = nn.Linear(d_model, d_model)\n",
    "        \n",
    "    def forward(self, query, key, value, time_diff, mask=None):\n",
    "        batch_size = query.size(0)\n",
    "        seq_length = query.size(1)\n",
    "        \n",
    "        Q = self.W_q(query)\n",
    "        K = self.W_k(key)\n",
    "        V = self.W_v(value)\n",
    "        \n",
    "        Q = Q.view(batch_size, seq_length, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        K = K.view(batch_size, seq_length, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        V = V.view(batch_size, seq_length, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        \n",
    "        time_diff = time_diff.unsqueeze(1).unsqueeze(1)  # [batch_size, 1, 1, seq_length]\n",
    "        time_diff = time_diff.expand(-1, self.num_heads, seq_length, -1)  # [batch_size, num_heads, seq_length, seq_length]\n",
    "        time_diff = torch.abs(time_diff.transpose(-1, -2) - time_diff)\n",
    "        \n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
    "        time_impact = torch.exp(-time_diff.clamp(min=-100, max=100))\n",
    "        scores = scores * time_impact\n",
    "        \n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(~mask.unsqueeze(1).unsqueeze(2), float('-inf'))\n",
    "        \n",
    "        attn = F.softmax(scores, dim=-1)\n",
    "        attn = torch.nan_to_num(attn, 0.0, 0.0, 0.0)  # Replace NaNs with zeros\n",
    "        context = torch.matmul(attn, V)\n",
    "        \n",
    "        context = context.transpose(1, 2).contiguous().view(batch_size, seq_length, self.d_model)\n",
    "        output = self.W_o(context)\n",
    "        \n",
    "        return output\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x, timestamps):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        # print(f\"In PositionalEncoding, x shape: {x.shape}, min: {x.min().item()}, max: {x.max().item()}\")\n",
    "        return self.dropout(x)\n",
    "\n",
    "class TransformerEncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.self_attn = TimeAwareMultiHeadAttention(d_model, num_heads)\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(d_model, d_ff),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d_ff, d_model)\n",
    "        )\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, time_diff, mask=None):\n",
    "        # Apply layer norm before self-attention\n",
    "        x_norm = self.norm1(x)\n",
    "        \n",
    "        attn_output = self.self_attn(x_norm, x_norm, x_norm, time_diff, mask)\n",
    "        # print(f\"After self-attention, output shape: {attn_output.shape}, min: {attn_output.min().item()}, max: {attn_output.max().item()}\")\n",
    "        \n",
    "        # Add residual connection\n",
    "        x = x + self.dropout(attn_output)\n",
    "        x = torch.nan_to_num(x, 0.0, 0.0, 0.0)  # Replace NaNs with zeros\n",
    "        # print(f\"After residual connection, x shape: {x.shape}, min: {x.min().item()}, max: {x.max().item()}\")\n",
    "        \n",
    "        # Apply layer norm before feed-forward\n",
    "        x_norm = self.norm2(x)\n",
    "        ff_output = self.feed_forward(x_norm)\n",
    "        # print(f\"After feed-forward, output shape: {ff_output.shape}, min: {ff_output.min().item()}, max: {ff_output.max().item()}\")\n",
    "        \n",
    "        # Add residual connection\n",
    "        x = x + self.dropout(ff_output)\n",
    "        x = torch.nan_to_num(x, 0.0, 0.0, 0.0)  # Replace NaNs with zeros\n",
    "        # print(f\"After second residual connection, x shape: {x.shape}, min: {x.min().item()}, max: {x.max().item()}\")\n",
    "        \n",
    "        return x\n",
    "\n",
    "class EHRTransformer(nn.Module):\n",
    "    def __init__(self, num_data_types, d_model, num_heads, num_layers, d_ff, dropout):\n",
    "        super().__init__()\n",
    "        self.data_type_embedding = nn.Embedding(num_data_types, d_model)\n",
    "        self.value_embedding = nn.Linear(1, d_model)\n",
    "        self.positional_encoding = PositionalEncoding(d_model)\n",
    "        \n",
    "        self.transformer_layers = nn.ModuleList([\n",
    "            TransformerEncoderLayer(d_model, num_heads, d_ff, dropout)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "        \n",
    "        self.output_layer = nn.Linear(d_model, d_model)\n",
    "        self.layer_norm = nn.LayerNorm(d_model)\n",
    "        \n",
    "    def forward(self, data_type, value, timestamp, time_diff, attention_mask):\n",
    "        # Embedding layers\n",
    "        data_type_emb = self.data_type_embedding(data_type)\n",
    "        value_emb = self.value_embedding(value.unsqueeze(-1))\n",
    "        \n",
    "        # Combine embeddings\n",
    "        x = data_type_emb + value_emb\n",
    "        x = torch.clamp(x, min=-100, max=100)  # Prevent extreme values\n",
    "        \n",
    "        # print(f\"After embedding, x shape: {x.shape}, min: {x.min().item()}, max: {x.max().item()}\")\n",
    "        \n",
    "        # Add positional encoding using timestamps\n",
    "        x = self.positional_encoding(x, timestamp)\n",
    "        x = torch.clamp(x, min=-100, max=100)  # Prevent extreme values\n",
    "        \n",
    "        # print(f\"After positional encoding, x shape: {x.shape}, min: {x.min().item()}, max: {x.max().item()}\")\n",
    "        \n",
    "        # Apply transformer layers\n",
    "        for i, layer in enumerate(self.transformer_layers):\n",
    "            x = layer(x, time_diff, attention_mask)\n",
    "            x = torch.clamp(x, min=-100, max=100)  # Prevent extreme values\n",
    "            x = torch.nan_to_num(x, 0.0, 0.0, 0.0)  # Replace NaNs with zeros\n",
    "            # print(f\"After transformer layer {i+1}, x shape: {x.shape}, min: {x.min().item()}, max: {x.max().item()}\")\n",
    "        \n",
    "        # Output layer with layer normalization\n",
    "        output = self.layer_norm(self.output_layer(x))\n",
    "        output = torch.clamp(output, min=-100, max=100)  # Prevent extreme values\n",
    "        output = torch.nan_to_num(output, 0.0, 0.0, 0.0)  # Replace NaNs with zeros\n",
    "        \n",
    "        # print(f\"Final output shape: {output.shape}, min: {output.min().item()}, max: {output.max().item()}\")\n",
    "        \n",
    "        return output\n",
    "\n",
    "# Example usage\n",
    "num_data_types = 100  # Adjust this based on your actual number of data types\n",
    "d_model = 128\n",
    "num_heads = 8\n",
    "num_layers = 6\n",
    "d_ff = 512\n",
    "dropout = 0.1\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Create the model and move it to the device\n",
    "model = EHRTransformer(num_data_types, d_model, num_heads, num_layers, d_ff, dropout).to(device)\n",
    "\n",
    "# Create the dataset and dataloader\n",
    "dataset = EHRDataset(preprocessed_data)\n",
    "dataloader = DataLoader(dataset, batch_size=512, shuffle=True, collate_fn=collate_fn, pin_memory=True)\n",
    "\n",
    "# Test the model with a batch\n",
    "for batch in dataloader:\n",
    "    # Move the entire batch to the device\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    \n",
    "    # Print the shape of the mask before passing it to the model\n",
    "    print(f\"Mask shape: {batch['mask'].shape}\")\n",
    "    \n",
    "    output = model(batch['data_type'], batch['value'], batch['timestamp'], batch['time_diff'], batch['mask'])\n",
    "    print(f\"Output shape: {output.shape}\")\n",
    "    break  # Just to check the first batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MaskedReconstructionLoss(nn.Module):\n",
    "    def __init__(self, continuous_features, num_categories):\n",
    "        super().__init__()\n",
    "        self.mse_loss = nn.MSELoss(reduction='none')\n",
    "        self.ce_loss = nn.CrossEntropyLoss(reduction='none', ignore_index=-1)\n",
    "        self.continuous_features = continuous_features\n",
    "        self.num_categories = num_categories\n",
    "\n",
    "    def forward(self, predictions, targets, data_type, mask_indices, attention_mask):\n",
    "        active_loss = (attention_mask.view(-1) == 1) & (mask_indices.view(-1) == 1)\n",
    "        active_preds = predictions.view(-1, predictions.size(-1))[active_loss]\n",
    "        active_targets = targets.view(-1)[active_loss]\n",
    "        active_data_type = data_type.view(-1)[active_loss]\n",
    "\n",
    "        cont_mask = torch.tensor([dt in self.continuous_features for dt in active_data_type])\n",
    "        cat_mask = ~cont_mask\n",
    "\n",
    "        total_loss = 0\n",
    "        num_samples = active_loss.sum()\n",
    "\n",
    "        if cont_mask.any():\n",
    "            cont_preds = active_preds[cont_mask, 0]\n",
    "            cont_targets = active_targets[cont_mask]\n",
    "            cont_loss = self.mse_loss(cont_preds, cont_targets).mean()\n",
    "            total_loss += cont_loss\n",
    "            # print(f\"Continuous Loss: {cont_loss.item():.4f}\")\n",
    "            # print(f\"Continuous Preds min/max: {cont_preds.min().item():.4f}/{cont_preds.max().item():.4f}\")\n",
    "            # print(f\"Continuous Targets min/max: {cont_targets.min().item():.4f}/{cont_targets.max().item():.4f}\")\n",
    "\n",
    "        if cat_mask.any():\n",
    "            cat_preds = active_preds[cat_mask]\n",
    "            cat_targets = active_targets[cat_mask].long()\n",
    "            cat_targets = torch.clamp(cat_targets, min=0, max=self.num_categories-1)\n",
    "            cat_loss = self.ce_loss(cat_preds, cat_targets).mean()\n",
    "            total_loss += cat_loss\n",
    "            # print(f\"Categorical Loss: {cat_loss.item():.4f}\")\n",
    "            # print(f\"Categorical Preds min/max: {cat_preds.min().item():.4f}/{cat_preds.max().item():.4f}\")\n",
    "            # print(f\"Categorical Targets min/max: {cat_targets.min().item()}/{cat_targets.max().item()}\")\n",
    "\n",
    "        return total_loss\n",
    "\n",
    "class ContrastiveLoss(nn.Module):\n",
    "    def __init__(self, temperature=0.5):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def forward(self, embeddings, patient_ids):\n",
    "        if torch.isnan(embeddings).any():\n",
    "            print(\"NaN detected in embeddings!\")\n",
    "            return torch.tensor(0.0, requires_grad=True)\n",
    "\n",
    "        embeddings = F.normalize(embeddings, p=2, dim=1)\n",
    "        \n",
    "        sim_matrix = torch.matmul(embeddings, embeddings.T) / self.temperature\n",
    "        \n",
    "        pos_mask = (patient_ids.unsqueeze(0) == patient_ids.unsqueeze(1)).float()\n",
    "        pos_mask.fill_diagonal_(0)\n",
    "        \n",
    "        if pos_mask.sum() == 0:\n",
    "            print(\"No positive pairs found in the batch!\")\n",
    "            return torch.tensor(0.0, requires_grad=True)\n",
    "\n",
    "        neg_mask = 1 - pos_mask\n",
    "        neg_mask.fill_diagonal_(0)\n",
    "\n",
    "        pos_sim = torch.exp(sim_matrix) * pos_mask\n",
    "        neg_sim = torch.exp(sim_matrix) * neg_mask\n",
    "\n",
    "        loss = -torch.log(pos_sim.sum(dim=1) / (pos_sim.sum(dim=1) + neg_sim.sum(dim=1) + 1e-8))\n",
    "        return loss.mean()\n",
    "        \n",
    "\n",
    "def mask_data(data, mask, mask_ratio=0.15):\n",
    "    mask_indices = torch.rand_like(data.float()) < mask_ratio\n",
    "    mask_indices = mask_indices & mask\n",
    "    masked_data = data.clone()\n",
    "    masked_data[mask_indices] = 0\n",
    "    return masked_data, mask_indices\n",
    "\n",
    "def train_epoch(model, dataloader, optimizer, continuous_features, num_categories, device, mask_ratio=0.15, clip_value=1.0):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    reconstruction_loss_fn = MaskedReconstructionLoss(continuous_features, num_categories).to(device)\n",
    "    contrastive_loss_fn = ContrastiveLoss().to(device)\n",
    "    \n",
    "    epoch_losses = {\n",
    "        'total': [],\n",
    "        'reconstruction': [],\n",
    "        'contrastive': []\n",
    "    }\n",
    "\n",
    "    for batch_idx, batch in enumerate(tqdm(dataloader, desc=\"Training\")):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Move individual tensors to device\n",
    "        data_type = batch['data_type'].to(device)\n",
    "        value = batch['value'].to(device)\n",
    "        timestamp = batch['timestamp'].to(device)\n",
    "        time_diff = batch['time_diff'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        patient_ids = batch['patient_id'].to(device)\n",
    "\n",
    "        masked_value, mask_indices = mask_data(value, attention_mask, mask_ratio)\n",
    "        mask_indices = mask_indices.to(device)\n",
    "\n",
    "        try:\n",
    "            output = model(data_type, masked_value, timestamp, time_diff, attention_mask)\n",
    "            \n",
    "            if torch.isnan(output).any():\n",
    "                print(f\"NaN detected in model output at batch {batch_idx}\")\n",
    "                print(f\"Input shapes: data_type {data_type.shape}, masked_value {masked_value.shape}, timestamp {timestamp.shape}, time_diff {time_diff.shape}, attention_mask {attention_mask.shape}\")\n",
    "                print(f\"Output shape: {output.shape}\")\n",
    "                print(f\"Output min/max: {output.min().item()}/{output.max().item()}\")\n",
    "                continue\n",
    "\n",
    "            recon_loss = reconstruction_loss_fn(output, value, data_type, mask_indices, attention_mask)\n",
    "            \n",
    "            mean_embedding = (output * attention_mask.unsqueeze(-1)).sum(dim=1) / (attention_mask.sum(dim=1, keepdim=True) + 1e-8)\n",
    "            contrastive_loss = contrastive_loss_fn(mean_embedding, patient_ids)\n",
    "\n",
    "            contrastive_weight = 0.1\n",
    "            loss = recon_loss + contrastive_weight * contrastive_loss\n",
    "\n",
    "            if not torch.isnan(loss) and not torch.isinf(loss):\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), clip_value)\n",
    "                optimizer.step()\n",
    "\n",
    "                total_loss += loss.item()\n",
    "                epoch_losses['total'].append(loss.item())\n",
    "                epoch_losses['reconstruction'].append(recon_loss.item())\n",
    "                epoch_losses['contrastive'].append(contrastive_loss.item())\n",
    "\n",
    "            # if batch_idx % 10 == 0:\n",
    "                # print(f\"Batch {batch_idx} losses - Total: {loss.item():.4f}, Recon: {recon_loss.item():.4f}, Contrastive: {contrastive_loss.item():.4f}\")\n",
    "                #print(f\"Unique patient IDs in batch: {patient_ids.unique().shape[0]}\")\n",
    "                #print(f\"Patient ID counts: {torch.bincount(patient_ids)}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error in batch {batch_idx}: {str(e)}\")\n",
    "            print(\"Batch keys:\", batch.keys())\n",
    "            for key, value in batch.items():\n",
    "                print(f\"{key} shape: {value.shape}\")\n",
    "            continue\n",
    "\n",
    "    return total_loss / len(dataloader), epoch_losses\n",
    "\n",
    "# In the main training loop\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)  # Reduced learning rate\n",
    "\n",
    "def train_model(model, dataloader, num_epochs, learning_rate, device, continuous_features, num_categories):\n",
    "    model = model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    all_losses = []\n",
    "    \n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        loss, epoch_losses = train_epoch(model, dataloader, optimizer, device, continuous_features, num_categories)\n",
    "        all_losses.append(epoch_losses)\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss:.4f}\")\n",
    "        \n",
    "    torch.cuda.synchronize()\n",
    "    \n",
    "    # Save losses to file\n",
    "    with open('training_losses.json', 'w') as f:\n",
    "        json.dump(all_losses, f)\n",
    "    print(\"Loss data saved to 'training_losses.json'\")\n",
    "    \n",
    "    # Plot losses\n",
    "    plot_losses(all_losses)\n",
    "\n",
    "    return model, all_losses\n",
    "\n",
    "def plot_losses(all_losses):\n",
    "    epochs = range(1, len(all_losses) + 1)\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Total Loss\n",
    "    total_losses = [np.mean(epoch['total']) for epoch in all_losses]\n",
    "    plt.plot(epochs, total_losses, label='Total Loss', marker='o')\n",
    "    print('total_losses:' + str(total_losses))\n",
    "    \n",
    "    # Reconstruction Loss\n",
    "    recon_losses = [np.mean(epoch['reconstruction']) for epoch in all_losses]\n",
    "    plt.plot(epochs, recon_losses, label='Reconstruction Loss', marker='s')\n",
    "    print('recon_losses:' + str(recon_losses))\n",
    "    \n",
    "    # Contrastive Loss\n",
    "    contrastive_losses = [np.mean(epoch['contrastive']) for epoch in all_losses]\n",
    "    plt.plot(epochs, contrastive_losses, label='Contrastive Loss', marker='^')\n",
    "    print('contrastive_losses:' + str(contrastive_losses))\n",
    "    plt.title('Training Losses over Epochs')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Save the plot\n",
    "    plt.savefig('training_losses.png')\n",
    "    print(\"Loss plot saved as 'training_losses.png'\")\n",
    "    \n",
    "    # Display the plot (if running in an interactive environment)\n",
    "    plt.show()\n",
    "    \n",
    "    # Close the plot to free up memory\n",
    "    plt.close()\n",
    "\n",
    "# Example usage\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_epochs = 2\n",
    "learning_rate = 1e-4\n",
    "continuous_features = ['hba1c', 'sbp', 'bmi', 'creat']  # Update this list based on your data\n",
    "num_categories = 100  # Set this to the number of categories in your categorical variables\n",
    "\n",
    "# model, losses = train_model(model, dataloader, num_epochs, learning_rate, device, continuous_features, num_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cpu\")\n",
    "# print(f\"Using device: {device}\")\n",
    "\n",
    "# # Set a smaller batch size\n",
    "# batch_size = 32\n",
    "\n",
    "# # Create the dataset\n",
    "# dataset = EHRDataset(preprocessed_data)\n",
    "\n",
    "# # Create the patient sampler\n",
    "# patient_sampler = PatientSampler(dataset, batch_size=batch_size)\n",
    "\n",
    "# # Create the dataloader\n",
    "# dataloader = DataLoader(dataset, batch_sampler=patient_sampler, collate_fn=collate_fn)\n",
    "\n",
    "# # Training loop\n",
    "# num_epochs = 2\n",
    "# model = EHRTransformer(num_data_types, d_model, num_heads, num_layers, d_ff, dropout).to(device)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "\n",
    "# for epoch in range(num_epochs):\n",
    "#     try:\n",
    "#         loss, epoch_losses = train_epoch(model, dataloader, optimizer, device, continuous_features, num_categories)\n",
    "#         print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss:.4f}\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error in epoch {epoch+1}: {str(e)}\")\n",
    "#         continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/3659 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 311/3659 [00:23<04:07, 13.50it/s]"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "def plot_losses(losses):\n",
    "    epochs = range(1, len(losses['total']) + 1)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(epochs, losses['total'], label='Total Loss')\n",
    "    plt.plot(epochs, losses['reconstruction'], label='Reconstruction Loss')\n",
    "    plt.plot(epochs, losses['contrastive'], label='Contrastive Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Training Losses')\n",
    "    plt.show()\n",
    "    \n",
    "# Create the dataset\n",
    "dataset = EHRDataset(preprocessed_data)\n",
    "\n",
    "# Create the patient sampler\n",
    "patient_sampler = PatientSampler(dataset, batch_size=batch_size)\n",
    "\n",
    "# Create the dataloader\n",
    "dataloader = DataLoader(dataset, batch_sampler=patient_sampler, collate_fn=collate_fn)\n",
    "\n",
    "# Training loop\n",
    "model = EHRTransformer(num_data_types, d_model, num_heads, num_layers, d_ff, dropout).to(device)\n",
    "\n",
    "# Assuming you have already defined and initialized your model, optimizer, dataloader, etc.\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 2\n",
    "all_losses = {'total': [], 'reconstruction': [], 'contrastive': []}\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss, epoch_losses = train_epoch(model, dataloader, optimizer, continuous_features, num_categories, device)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}\")\n",
    "    \n",
    "    all_losses['total'].append(sum(epoch_losses['total']) / len(epoch_losses['total']))\n",
    "    all_losses['reconstruction'].append(sum(epoch_losses['reconstruction']) / len(epoch_losses['reconstruction']))\n",
    "    all_losses['contrastive'].append(sum(epoch_losses['contrastive']) / len(epoch_losses['contrastive']))\n",
    "\n",
    "# Plot losses\n",
    "plot_losses(all_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
